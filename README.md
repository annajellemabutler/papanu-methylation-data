# Investigating Baboon DNA Methylation Changes With Age

*Winter 2024 Rotation Project*
*Soojin Yi Lab* 

Pipeline for the recreation of a [chapter of Hyeonsoo Jeong's thesis](https://docs.google.com/document/d/1TZFuVnaIoU6e3bUsUtpBu0H6r37STyjj/edit), including: (1) analysis of DNA methylation data from anubis baboons, (2) development of an aging CpG clock, and (3) further exploratory analysis relating to the relationship between epigenetic aging and early life rearing experience. 

### Data
The data were generated by reduced-representation bisulfite sequencing of blood-derived DNA from 140 *Papio anubis* baboons of a broad age-span. RRBS libraries were constructed using the NuGEN Library Preparation kit and sequenced on an Illumina HiSeq3000 system using 57 bp single-end reads. 

### Noobie Notes [^1]
- Installed miniconda using [this tutorial](https://github.com/um-dang/conda_on_the_cluster?tab=readme-ov-file)
- Created a project-specific environment (`dnam`) containing the relevant packages.
- There are several steps that must be taken every time you log-in to the cluster:
  - For any significant jobs (beyond basic file editing and transfer), you must         move from the login node to a compute node. You can do this by submitting a job to the Slurm scheduler using `sbatch` (this is good for long-running jobs) or by requesting an interactive computing node using `srun` (e.g., `srun -N 1 -n 4 -p batch --time=4:00:00 --pty bash -i`)(this is good for compiling, installing, testing code; real-time data exploration).
  - Activate the project environment

## 1. DNA Methylation Data Analysis
> [!NOTE]
I am currently working through a **trial run** using a single sample (`home/annajellema/trial_run/rawdata/10007_S29_L005_R1_001.fastq.gz`) before attempting to run the pipeline on all the files. 

### Overview of Pipeline 
1. Quality control (trimming, adaptor removal)
2. Bismark read alignment and methylation calling
3. De-duplication
4. Methylation extraction (optional step)

### Quality Control 
#### Trim Galore!
- Created script (`trial_trimgalore.sh`) to run Trim Galore v.0.4.1.
  - `trim_galore` combines `Cutadapt` (adapter trimming) and `FastQC` (quality control): low-quality base calls are trimmed from the 3' end; 3' adapter sequences are removed; trimmed reads < 20 bp are filtered out. 
  - Note, the `--rrbs` option (which removes the artificial methylation signal introduced by RRBS sequencing preparation) was not used because NuGEN method attaches a varying number of nucleotides after each MsPI site. Instead, use the diversity trimming step, below. 
- On a compute node, ran `bash trial_trimgalore.sh`. Output was sent to `~/trial_run/trimdata`.
  - Note, when repeating, run the script using `sbatch` (it took forever).

#### NugEN Diversity Adaptor Trimming
- Downloaded the script [provided by NuGEN](https://github.com/nugentechnologies/NuMetRRBS) and re-named it `~/trial_run/scripts/nugen_adaptor.py`.
  - The script trims 5 bases from the 3' end and 0-3 bp at the 5' end to remove the diversity sequences.
  - Any reads that don't contain a 5' MspI site signature (`YGG`, where `Y` is `C` or `T`) are removed. 
- Created a slurm script (`trial_nugen.slurm`) to feed the `trim_galore` output into the python script and ran `sbatch ~/trial_run/scripts/trial_nugen.slurm`.
- Output was new file(s) with `_trimmed.fq` appended to the filename.


### Alignment to Reference Genome
Bismark v 0.14. was used to align sequencing reads to the baboon papAnu4 reference genome and perform methylation calling concurrently. There are two steps to running Bismark:

#### (a) Genome preparation 
- Ran `bismark_genome_preparation --verbose /home/annajellema/papanu/refgenome`
  - Bismark prepares two folders for its output and carries out the bisulite conversions (all `C`s to `T`s and all `G`s to `A`s).
  - The `bowtie2` indexer is launched to index the converted genomes in parallel (indexing allows for efficient mapping). 
    
#### (b) Read alignment
- Created a job script (`trial_bismark.slurm`) and ran `sbatch ~/trial_run/scripts/trial_bismark.slurm`.
  - Accidentally deleted the output file (re-running with Job-ID 3235239)
- Bismark produces an alignment and methylation call output file (`*.bam`).

>QUESTION: Is there a way to check resources used by the job (Job-ID 3435030)? I could not get seff to work. It took ~8 hours.

### De-duplication
- On an interactive node, ran `deduplicate_bismark --bam --single 10007_S29_L005_R1_001_trimmed.fq_trimmed_bismark_bt2.bam`
  - This removes alignments to the same position in the genome (ie..e, if the start and end co-ordinate of the mapped read coincides with any other read, it gets discarded). These can arise due to excessive PCR amplifcation (i.e. PCR duplicates).
> QUESTION: Quote from [felixkrueger](https://felixkrueger.github.io/Bismark/bismark/deduplication/): "It is important to note that deduplication is not recommended for RRBS, amplicon or other target enrichment-type libraries!"

### Methylation extraction
- This step was not part of the original analysis.
- On an interactive node, ran `bismark_methylation_extractor -p --bedGraph --counts blah_R1.trim_bismark_bt2_pe.deduplicated.bam`.
  - Script extracts methylation call for every C analyzed.
  - It produces *.cov files for downstream analysis. Plan to import resulting file into genome viewer to visualize methylation data. 

## 2. Building a CpG Aging Clock 

### Controlling for local genetic variation
- Need to remove polymorphic CpGs because genetic polymorphisms of thymine at CpG sites are not distinguishable from bisulfite-converted cytosines.
- Download the [genetic variants data](https://doi.org/10.5281/zenodo.2583266), maybe for one baboon to start. These are catalogs of the SNPs in WGS sequences from _Papio_ baboons.
- Somehow parse the data to identify polymorphic CpGs and their corresponding positions, and then filter out those CpG sites from the data?


[^1]: This was my first time working on a HPC or large-scale data. 
